{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e7809-27f6-4b07-b9ab-a9b99e52e4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip instal requests numpy pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72dc3ef4-da75-4a6c-a915-84a063c02c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "import time\n",
    "import json\n",
    "from multiprocessing import Pool, cpu_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32868cc1-c528-42b9-a69d-93ab31f22cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv = \"./locations/locations_chunk_01.csv\"\n",
    "locations_df = pd.read_csv(input_csv)\n",
    "locations_df = locations_df.rename(columns={\"lat\": \"latitude\", \"lng\": \"longitude\"})\n",
    "locations = locations_df[[\"latitude\", \"longitude\"]].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74032939-b825-4ed1-bc00-fd635c383117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_monthly_weather(lat, lon, year, month):\n",
    "    start_date = datetime.date(year, month, 1)\n",
    "    end_date = datetime.date(year + 1, 1, 1) - datetime.timedelta(days=1) if month == 12 else \\\n",
    "               datetime.date(year, month + 1, 1) - datetime.timedelta(days=1)\n",
    "\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"start_date\": start_date.isoformat(),\n",
    "        \"end_date\": end_date.isoform at(),\n",
    "        \"daily\": \",\".join([\n",
    "            \"temperature_2m_max\", \"temperature_2m_min\", \"relative_humidity_2m_mean\",\n",
    "            \"cloud_cover_mean\", \"windspeed_10m_max\", \"windgusts_10m_max\",\n",
    "            \"precipitation_sum\", \"precipitation_hours\", \"sunshine_duration\",\n",
    "            \"shortwave_radiation_sum\", \"daylight_duration\"\n",
    "        ]),\n",
    "        \"timezone\": \"auto\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params, timeout=30)\n",
    "    data = response.json().get(\"daily\", {})\n",
    "\n",
    "    def safe_mean(key):\n",
    "        values = [v for v in data.get(key, []) if v is not None]\n",
    "        return round(np.mean(values), 2) if values else None\n",
    "\n",
    "    def safe_sum(key):\n",
    "        values = [v for v in data.get(key, []) if v is not None]\n",
    "        return round(np.sum(values), 2) if values else None\n",
    "\n",
    "    return {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": lon,\n",
    "        \"month\": f\"{year}-{month:02d}\",\n",
    "        \"temperature_max\": safe_mean(\"temperature_2m_max\"),\n",
    "        \"temperature_min\": safe_mean(\"temperature_2m_min\"),\n",
    "        \"humidity_mean\": safe_mean(\"relative_humidity_2m_mean\"),\n",
    "        \"cloud_cover_mean\": safe_mean(\"cloud_cover_mean\"),\n",
    "        \"windspeed_max\": safe_mean(\"windspeed_10m_max\"),\n",
    "        \"windgusts_max\": safe_mean(\"windgusts_10m_max\"),\n",
    "        \"precipitation_total\": safe_sum(\"precipitation_sum\"),\n",
    "        \"precipitation_hours\": safe_sum(\"precipitation_hours\"),\n",
    "        \"sunshine_hours\": round(safe_sum(\"sunshine_duration\") / 3600, 2) if safe_sum(\"sunshine_duration\") else None,\n",
    "        \"solar_radiation_GHI\": safe_sum(\"shortwave_radiation_sum\"),\n",
    "        \"daylight_hours\": round(safe_mean(\"daylight_duration\") / 3600, 2) if safe_mean(\"daylight_duration\") else None\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bedc35b2-f962-4516-9c14-d30f06012162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️ Total tasks: 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [00:10<00:00, 17.47it/s]\n"
     ]
    }
   ],
   "source": [
    "year = 2023\n",
    "NUM_PROCESSES = min(16, cpu_count())  # Adjust as needed\n",
    "\n",
    "# Generate all tasks\n",
    "tasks = []\n",
    "for lat, lon in locations:\n",
    "    for month in range(1, 13):\n",
    "        tasks.append((lat, lon, year, month))\n",
    "\n",
    "print(f\"⚙️ Total tasks: {len(tasks)}\")\n",
    "\n",
    "def task_wrapper(args):\n",
    "    lat, lon, year, month = args\n",
    "    try:\n",
    "        return get_monthly_weather(lat, lon, year, month)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed for ({lat},{lon}) {month}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Run in parallel\n",
    "with Pool(NUM_PROCESSES) as pool:\n",
    "    results = list(tqdm(pool.imap(task_wrapper, tasks), total=len(tasks)))\n",
    "    all_weather_data = [r for r in results if r is not None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a180c965-88d3-4777-8955-129b3c3f662c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV saved: ./outputs/chunck_01.csv\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "output_csv = \"./outputs/chunck_01.csv\"\n",
    "final_df = pd.DataFrame(all_weather_data)\n",
    "final_df.to_csv(output_csv, index=False)\n",
    "print(f\"✅ CSV saved: {output_csv}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec63237-6b16-41a5-9baf-5f7c34c00331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save flat JSON\n",
    "output_json_flat = \"weather_data_all_locations_2023.json\"\n",
    "final_df.to_json(output_json_flat, orient=\"records\", indent=2)\n",
    "print(f\"✅ Flat JSON saved: {output_json_flat}\")\n",
    "\n",
    "# Save grouped JSON\n",
    "output_json_grouped = \"weather_data_grouped_by_location.json\"\n",
    "grouped = {}\n",
    "for record in all_weather_data:\n",
    "    key = f\"{record['latitude']},{record['longitude']}\"\n",
    "    month_data = {k: v for k, v in record.items() if k not in ['latitude', 'longitude']}\n",
    "    grouped.setdefault(key, []).append(month_data)\n",
    "\n",
    "with open(output_json_grouped, \"w\") as f:\n",
    "    json.dump(grouped, f, indent=2)\n",
    "print(f\"✅ Grouped JSON saved: {output_json_grouped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00356892-3833-4671-9fd9-e48597a60392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Missing (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sunshine_hours</td>\n",
       "      <td>3904</td>\n",
       "      <td>54.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>daylight_hours</td>\n",
       "      <td>3903</td>\n",
       "      <td>54.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>humidity_mean</td>\n",
       "      <td>3901</td>\n",
       "      <td>54.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cloud_cover_mean</td>\n",
       "      <td>3901</td>\n",
       "      <td>54.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>temperature_min</td>\n",
       "      <td>3901</td>\n",
       "      <td>54.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>temperature_max</td>\n",
       "      <td>3901</td>\n",
       "      <td>54.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>precipitation_total</td>\n",
       "      <td>3901</td>\n",
       "      <td>54.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>windgusts_max</td>\n",
       "      <td>3901</td>\n",
       "      <td>54.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>precipitation_hours</td>\n",
       "      <td>3901</td>\n",
       "      <td>54.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>windspeed_max</td>\n",
       "      <td>3901</td>\n",
       "      <td>54.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>solar_radiation_GHI</td>\n",
       "      <td>3901</td>\n",
       "      <td>54.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>month</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>latitude</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>longitude</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Column  Missing Values  Missing (%)\n",
       "11       sunshine_hours            3904        54.23\n",
       "13       daylight_hours            3903        54.22\n",
       "5         humidity_mean            3901        54.19\n",
       "6      cloud_cover_mean            3901        54.19\n",
       "4       temperature_min            3901        54.19\n",
       "3       temperature_max            3901        54.19\n",
       "9   precipitation_total            3901        54.19\n",
       "8         windgusts_max            3901        54.19\n",
       "10  precipitation_hours            3901        54.19\n",
       "7         windspeed_max            3901        54.19\n",
       "12  solar_radiation_GHI            3901        54.19\n",
       "2                 month               0         0.00\n",
       "0              latitude               0         0.00\n",
       "1             longitude               0         0.00"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your file (adjust path if needed)\n",
    "df = pd.read_csv(\"combined_ANR_chunks_2_to_11.csv\")\n",
    "\n",
    "# Count missing values\n",
    "missing_count = df.isnull().sum()\n",
    "missing_pct = df.isnull().mean() * 100\n",
    "\n",
    "# Combine into a summary table\n",
    "missing_summary = pd.DataFrame({\n",
    "    \"Missing Values\": missing_count,\n",
    "    \"Missing (%)\": missing_pct.round(2)\n",
    "}).reset_index().rename(columns={\"index\": \"Column\"})\n",
    "\n",
    "# Sort by most missing\n",
    "missing_summary = missing_summary.sort_values(\"Missing Values\", ascending=False)\n",
    "\n",
    "# Display summary\n",
    "missing_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "666e4f33-425a-440b-afa5-74c75acea53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-6.0.1-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting narwhals>=1.15.1 (from plotly)\n",
      "  Downloading narwhals-1.38.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from plotly) (24.1)\n",
      "Downloading plotly-6.0.1-py3-none-any.whl (14.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading narwhals-1.38.0-py3-none-any.whl (338 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m338.3/338.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: narwhals, plotly\n",
      "Successfully installed narwhals-1.38.0 plotly-6.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e200b013-1346-4d37-9356-a4bb2978f045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Load the raw dataset\n",
    "df = pd.read_csv(\"combined_ANR_chunks_2_to_11.csv\")\n",
    "\n",
    "# Define columns to check for missing values (exclude lat, lon, month)\n",
    "non_weather = [\"latitude\", \"longitude\", \"month\"]\n",
    "weather_cols = [col for col in df.columns if col not in non_weather]\n",
    "\n",
    "# Drop rows with missing weather data\n",
    "df_cleaned = df.dropna(subset=weather_cols)\n",
    "\n",
    "# Save cleaned file\n",
    "df_cleaned.to_csv(\"weather_data_cleaned.csv\", index=False)\n",
    "print(f\"✅ Cleaned file saved: {len(df_cleaned)} rows\")\n",
    "\n",
    "# Downloadable version path\n",
    "cleaned_file_path = \"weather_data_cleaned.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb2d52ba-37fe-4fb6-bf3c-1372c784c6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 299 unique locations to: unique_cleaned_locations.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df_cleaned = pd.read_csv(\"weather_data_cleaned.csv\")\n",
    "\n",
    "# Extract unique latitude/longitude pairs\n",
    "unique_locations = df_cleaned[[\"latitude\", \"longitude\"]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Save to CSV\n",
    "unique_locations.to_csv(\"unique_cleaned_locations.csv\", index=False)\n",
    "print(f\"✅ Saved {len(unique_locations)} unique locations to: unique_cleaned_locations.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd2f40b-4698-4fc4-b567-b94247164e64",
   "metadata": {},
   "source": [
    "### Solar PVWatts api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aee7a251-8deb-46df-9cb2-7c796a712f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching PVWatts: 100%|██████████| 40365/40365 [56:51<00:00, 11.83it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Completed. Output saved to: pvwatts_parallel_output.jsonl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import itertools\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock\n",
    "\n",
    "# === CONFIG ===\n",
    "LOCATIONS_CSV = \"unique_cleaned_locations.csv\"\n",
    "API_KEYS_CSV = \"api_keys.csv\"\n",
    "OUTPUT_FILE = \"pvwatts_parallel_output.jsonl\"\n",
    "MAX_WORKERS = 50  # adjust depending on your CPU and network\n",
    "\n",
    "# === Load Input Data ===\n",
    "locations_df = pd.read_csv(LOCATIONS_CSV)\n",
    "locations = list(zip(locations_df['latitude'], locations_df['longitude']))\n",
    "\n",
    "api_keys_df = pd.read_csv(API_KEYS_CSV)\n",
    "api_keys = api_keys_df['API KEY'].dropna().tolist()\n",
    "\n",
    "# === Thread-safe API key rotation ===\n",
    "api_index = 0\n",
    "api_lock = Lock()\n",
    "\n",
    "def get_next_api_key():\n",
    "    global api_index\n",
    "    with api_lock:\n",
    "        key = api_keys[api_index % len(api_keys)]\n",
    "        api_index += 1\n",
    "    return key\n",
    "\n",
    "# === Generate Configurations ===\n",
    "def generate_configs(lat, lon):\n",
    "    tilts = [20, 30, 40, 45, 50]\n",
    "    azimuths = [90, 180, 270]\n",
    "    module_types = [0, 1, 2]\n",
    "    array_types = [1, 2, 3]\n",
    "    combos = list(itertools.product(tilts, azimuths, module_types, array_types))\n",
    "\n",
    "    rows = []\n",
    "    for tilt, az, mod, arr in combos:\n",
    "        rows.append({\n",
    "            \"lat\": lat,\n",
    "            \"lon\": lon,\n",
    "            \"tilt\": tilt,\n",
    "            \"azimuth\": az,\n",
    "            \"module_type\": mod,\n",
    "            \"array_type\": arr,\n",
    "            \"system_capacity\": 1.0,\n",
    "            \"losses\": 14.0\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "# === Call PVWatts API ===\n",
    "def call_pvwatts(row):\n",
    "    api_key = get_next_api_key()\n",
    "    base_url = \"https://developer.nrel.gov/api/pvwatts/v8.json\"\n",
    "    url = (\n",
    "        f\"{base_url}?api_key={api_key}\"\n",
    "        f\"&lat={row['lat']}&lon={row['lon']}\"\n",
    "        f\"&system_capacity={row['system_capacity']}\"\n",
    "        f\"&module_type={row['module_type']}&array_type={row['array_type']}\"\n",
    "        f\"&tilt={row['tilt']}&azimuth={row['azimuth']}\"\n",
    "        f\"&losses={row['losses']}&dataset=nsrdb&radius=0\"\n",
    "    )\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        return {\n",
    "            \"lat\": row[\"lat\"],\n",
    "            \"lon\": row[\"lon\"],\n",
    "            \"config\": {k: row[k] for k in [\"tilt\", \"azimuth\", \"module_type\", \"array_type\"]},\n",
    "            \"response\": response.json()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"lat\": row[\"lat\"],\n",
    "            \"lon\": row[\"lon\"],\n",
    "            \"config\": {k: row[k] for k in [\"tilt\", \"azimuth\", \"module_type\", \"array_type\"]},\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "# === Prepare all jobs\n",
    "all_jobs = []\n",
    "for lat, lon in locations:\n",
    "    all_jobs.extend(generate_configs(lat, lon))\n",
    "\n",
    "# === Run in parallel\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = [executor.submit(call_pvwatts, job) for job in all_jobs]\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Fetching PVWatts\"):\n",
    "        results.append(future.result())\n",
    "\n",
    "# === Save output to JSONL\n",
    "with open(OUTPUT_FILE, \"w\") as f:\n",
    "    for result in results:\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "print(f\"\\n✅ Completed. Output saved to: {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0f4b6b2-4094-4555-a1b0-f815dde4c7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Cleaned output written to: pvwatts_cleaned.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_file = \"./pvwatts_parallel_output.jsonl\"\n",
    "output_file = \"pvwatts_cleaned.jsonl\"\n",
    "\n",
    "with open(input_file, \"r\") as fin, open(output_file, \"w\") as fout:\n",
    "    for line in fin:\n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "            config = data.get(\"config\", {})\n",
    "            outputs = data.get(\"response\", {}).get(\"outputs\", {})\n",
    "            cleaned = {\n",
    "                \"config\": config,\n",
    "                \"ac_monthly\": outputs.get(\"ac_monthly\"),\n",
    "                \"dc_monthly\": outputs.get(\"dc_monthly\"),\n",
    "                \"solrad_monthly\": outputs.get(\"solrad_monthly\")\n",
    "            }\n",
    "            fout.write(json.dumps(cleaned) + \"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping a line due to error: {e}\")\n",
    "\n",
    "print(f\"\\n✅ Cleaned output written to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "269af582-0b44-4f95-919b-75d25794c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv(\"weather_data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cec0e27d-bcec-4991-b608-cdba35fa169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming your column is called 'month' in weather_df\n",
    "weather_df[\"month\"] = weather_df[\"month\"].str[-2:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c3e3120-e401-4dd3-9df1-89ba58b162c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.to_csv(\"weather_data_cleaned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe309c1-25a2-4e5f-ba23-2f0fbaad2fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged 3295 rows (by lat, lon, and month) saved to merged_output_by_location.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import itertools\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock\n",
    "\n",
    "# === CONFIG ===\n",
    "LOCATIONS_CSV = \"unique_cleaned_locations.csv\"\n",
    "API_KEYS_CSV = \"api_keys.csv\"\n",
    "OUTPUT_FILE = \"pvwatts_parallel_output.jsonl\"\n",
    "MAX_WORKERS = 50  # adjust depending on your CPU and network\n",
    "\n",
    "# === Load Input Data ===\n",
    "locations_df = pd.read_csv(LOCATIONS_CSV)\n",
    "locations = list(zip(locations_df['latitude'], locations_df['longitude']))\n",
    "\n",
    "api_keys_df = pd.read_csv(API_KEYS_CSV)\n",
    "api_keys = api_keys_df['API KEY'].dropna().tolist()\n",
    "\n",
    "# === Thread-safe API key rotation ===\n",
    "api_index = 0\n",
    "api_lock = Lock()\n",
    "\n",
    "def get_next_api_key():\n",
    "    global api_index\n",
    "    with api_lock:\n",
    "        key = api_keys[api_index % len(api_keys)]\n",
    "        api_index += 1\n",
    "    return key\n",
    "\n",
    "# === Generate Configurations ===\n",
    "def generate_configs(lat, lon):\n",
    "    tilts = [20, 30, 40, 45, 50]\n",
    "    azimuths = [90, 180, 270]\n",
    "    module_types = [0, 1, 2]\n",
    "    array_types = [1, 2, 3]\n",
    "    combos = list(itertools.product(tilts, azimuths, module_types, array_types))\n",
    "\n",
    "    rows = []\n",
    "    for tilt, az, mod, arr in combos:\n",
    "        rows.append({\n",
    "            \"lat\": lat,\n",
    "            \"lon\": lon,\n",
    "            \"tilt\": tilt,\n",
    "            \"azimuth\": az,\n",
    "            \"module_type\": mod,\n",
    "            \"array_type\": arr,\n",
    "            \"system_capacity\": 1.0,\n",
    "            \"losses\": 14.0\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "# === Call PVWatts API ===\n",
    "def call_pvwatts(row):\n",
    "    api_key = get_next_api_key()\n",
    "    base_url = \"https://developer.nrel.gov/api/pvwatts/v8.json\"\n",
    "    url = (\n",
    "        f\"{base_url}?api_key={api_key}\"\n",
    "        f\"&lat={row['lat']}&lon={row['lon']}\"\n",
    "        f\"&system_capacity={row['system_capacity']}\"\n",
    "        f\"&module_type={row['module_type']}&array_type={row['array_type']}\"\n",
    "        f\"&tilt={row['tilt']}&azimuth={row['azimuth']}\"\n",
    "        f\"&losses={row['losses']}&dataset=nsrdb&radius=0\"\n",
    "    )\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        return {\n",
    "            \"lat\": row[\"lat\"],\n",
    "            \"lon\": row[\"lon\"],\n",
    "            \"config\": {k: row[k] for k in [\"tilt\", \"azimuth\", \"module_type\", \"array_type\"]},\n",
    "            \"response\": response.json()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"lat\": row[\"lat\"],\n",
    "            \"lon\": row[\"lon\"],\n",
    "            \"config\": {k: row[k] for k in [\"tilt\", \"azimuth\", \"module_type\", \"array_type\"]},\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "# === Prepare all jobs\n",
    "all_jobs = []\n",
    "for lat, lon in locations:\n",
    "    all_jobs.extend(generate_configs(lat, lon))\n",
    "\n",
    "# === Run in parallel\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = [executor.submit(call_pvwatts, job) for job in all_jobs]\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Fetching PVWatts\"):\n",
    "        results.append(future.result())\n",
    "\n",
    "# === Save output to JSONL\n",
    "with open(OUTPUT_FILE, \"w\") as f:\n",
    "    for result in results:\n",
    "        f.write(json.dumps(result) + \"\\n\")\n",
    "\n",
    "print(f\"\\n✅ Completed. Output saved to: {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49043a47",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263ceccd-50e7-4b46-99e9-bbf71394eb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
